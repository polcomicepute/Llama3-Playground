{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ollama\n",
    "- Llama3, 등 여러가지 LLM 모델을 다운로드 후, local에서 실행 및 관리 가능한 툴\n",
    "- 클라우드 기반 or API Hosting 없이 로컬환경에서 offline으로 보안적으로 사용 가능 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOW TO USE\n",
    "1. Download ollama at Linux\n",
    "\t`curl -fsSL https://ollama.com/install.sh | sh` \n",
    "2. Execute  \n",
    "   \n",
    "\tat shell 1\n",
    "\t- run ollama: `ollama serve`  \n",
    "  \n",
    "\tanother shell(2) \n",
    "\t- download llama3: `ollama pull llama3`\n",
    "\t\t- `ollama pull llama3` to download the Llama 3 8b chat model, in the 4-bit quantized format with size about 4.7 GB.\n",
    "\t\t- Run `ollama pull llama3:70b` to download the Llama 3 70b chat model, also in the 4-bit quantized format with size 39GB.\n",
    "\t- run llama3 model : `ollama run llama3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"http://localhost:11434/api/chat\"\n",
    "\n",
    "def llama3(prompt):\n",
    "    data = {\n",
    "        \"model\":\"llama3\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        \"stream\": False\n",
    "    }\n",
    "    headers = {\n",
    "        'Content-Type' : 'application/json'\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers = headers, json=data)\n",
    "    \n",
    "    return(response.json()['message']['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A fun question!\n",
      "\n",
      "When given the command \"Water, please\", the robot needs to move to and interact with a water source. Here are three common locations where water might be found:\n",
      "\n",
      "1. **Kitchen sink**: The robot may need to navigate to the kitchen area, then approach the sink to access the faucet or tap.\n",
      "2. **Water dispenser** (e.g., water cooler): In an office setting, the robot might move to a water dispenser, such as a water cooler or a water fountain, to access drinking water.\n",
      "3. **Garden hose**: If the command is related to watering plants, the robot could move to an outdoor location with a garden hose, such as a backyard or a greenhouse.\n",
      "\n",
      "As for the actions the robot needs to perform:\n",
      "\n",
      "1. **Locate the water source**: The robot must identify and approach the water source.\n",
      "2. **Grasp the water** (if possible): Using its manipulator arm, the robot might need to grasp a water bottle, faucet handle, or hose nozzle to access the water.\n",
      "3. **Pour or dispense water** (if applicable): If the robot is equipped with a liquid-handling capability, it may need to pour or dispense water from a container, such as a water bottle or bucket.\n",
      "\n",
      "Please note that these actions might vary depending on the specific context and design of the robot.\n"
     ]
    }
   ],
   "source": [
    "robot_command = \"\"\"The robot is equipped with wheels and a manipulator arm.\n",
    "When given the command \"Water, please\" to the robot:\n",
    "\n",
    "1. What locations does the robot need to move to in order to execute the command? Please provide at least three common locations where that is typically found.\n",
    "2. What actions does the robot need to perform?\"\"\" \n",
    "# Bring me some water.\n",
    "response = llama3(robot_command)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고 자료\n",
    "- https://github.com/ollama/ollama/blob/main/README.md#quickstart\n",
    "- https://github.com/ollama/ollama/blob/main/docs/api.md"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3e8158a314f02ec0c390a43a5045b72062fab839463d13d14c6a1f932c8ca7c9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.18 ('nuplan': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
